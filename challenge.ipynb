{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchpress Hackathon\n",
    "\n",
    "The challenge comes with a Jupyter notebook for your implementation and various utilities.\n",
    "We provide a development set and a validation set you can use to develop your solution.\n",
    "The development set is for testing your code and consists of 300 problems with a varying number of test cases.\n",
    "You are free to use all data provided with a problem, a sample has the following structure:\n",
    "\n",
    "```python\n",
    "{\n",
    "    # Unique identifier for the problem in the APPS dataset.\n",
    "    \"problem_id\": 4424,\n",
    "    # The problem statement\n",
    "    \"question\": \"Given three integers ...\",\n",
    "    # The expected function name and the input/output examples\n",
    "    # representing test cases.\n",
    "    \"input_output\": {\n",
    "        \"fn_name\": \"expression_matter\",\n",
    "        \"inputs\": [ ... ],\n",
    "        \"outputs\": [ ... ]\n",
    "    },\n",
    "    \"url\": \"https://www.codewars.com/kata/5ae62fcf252e66d44d00008e\",\n",
    "    \"difficulty\": \"introductory\",\n",
    "    # The starter code for the problem.\n",
    "    \"starter_code\": \"def expression_matter(a, b, c):\\n\\t\"\n",
    "}\n",
    "```\n",
    "\n",
    "The validation set is consists of 200 problems, and includes an additional key `test_cases` which is used to score your solution with the provided scoring function.\n",
    "\n",
    "```python\n",
    "{\n",
    "    ...\n",
    "    \"test_cases\": {\n",
    "        \"fn_name\": \"expression_matter\",\n",
    "        \"inputs\": [ ... ],\n",
    "        \"outputs\": [ ... ]\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "### Loading Problems\n",
    "\n",
    "Use the `load_sample` function to load a problem from the development or validation set.\n",
    "\n",
    "```python\n",
    "from utilities import load_sample\n",
    "\n",
    "problem = load_sample(index=0, dataset_path=\"./data/dev\")\n",
    "```\n",
    "\n",
    "### Generating Code\n",
    "\n",
    "Use the `aleph_alpha_client` to generate code.\n",
    "Make sure your `AA_TOKEN` is set.\n",
    "\n",
    "```python\n",
    "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
    "\n",
    "client = Client(AA_TOKEN)\n",
    "\n",
    "request = CompletionRequest(\n",
    "    prompt=Prompt.from_text(\"Your prompt.\"),\n",
    "    maximum_tokens=256,\n",
    ")\n",
    "\n",
    "# API reference for the client:\n",
    "# https://aleph-alpha-client.readthedocs.io/en/latest/\n",
    "response = client.complete(request, model=MODEL)\n",
    "```\n",
    "\n",
    "### Running Tests\n",
    "\n",
    "Use the `run_test_cases` function to run the generated code against the test cases.\n",
    "The function returns a dictionary with the test results, including the expected output, the generated output, a boolean indicating whether the test passed and a traceback in case of an error.\n",
    "\n",
    "```python\n",
    "from utilities import run_test_cases\n",
    "\n",
    "test_results = run_test_cases(\n",
    "    problem=problem, \n",
    "    generation=response.completions[0].completion, \n",
    "    timeout=10,\n",
    ")\n",
    "```\n",
    "\n",
    "### Scoring\n",
    "\n",
    "Use the `score` function to score your solution on the validation set.\n",
    "It expects a function that takes a problem and a client and returns a generation.\n",
    "\n",
    "```python\n",
    "from utilities import score\n",
    "\n",
    "passed_problems, passed_test_cases = score(\n",
    "    generation_func=generate_code, \n",
    "    client=client,\n",
    "    dataset_path=\"./data/val\", \n",
    "    length=50,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:04:37.549719Z",
     "start_time": "2024-11-22T15:04:36.622529Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "AA_TOKEN = \"\"\n",
    "MODEL = \"llama-3.1-70b-instruct\"\n",
    "\n",
    "if AA_TOKEN is None:\n",
    "    raise ValueError(\"Aleph Alpha Playground token is not set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['problem_id', 'question', 'input_output', 'url', 'difficulty', 'starter_code']\n",
      "def expression_matter(a, b, c):\n",
      "    return max(a * (b + c), a + b * c, (a + b) * c, a + b + c)\n"
     ]
    }
   ],
   "source": [
    "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
    "from utilities import load_sample, run_test_cases\n",
    "\n",
    "\n",
    "client = Client(AA_TOKEN)\n",
    "\n",
    "\n",
    "def generate_prompt(problem: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate a prompt for a given problem.\n",
    "    \n",
    "    Args:\n",
    "        problem (dict): A dictionary containing the problem, test cases, and starter code.\n",
    "    \n",
    "    Returns:\n",
    "        str: A prompt for the given problem.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = \"\\nQUESTION:\\n\"\n",
    "    prompt += problem[\"question\"]\n",
    "    prompt += \"\\n\\nSTARTER CODE:\\n\"\n",
    "    prompt += problem[\"starter_code\"]\n",
    "    prompt += \"\\n\\nWrite only the code, directly executable, no tests or other comments.\"\n",
    "    prompt += \" Don't use markdown code blocks.\"\n",
    "    prompt += \"\\n\\nCODE:\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_code(problem: dict, client: Client) -> str:\n",
    "    print(list(problem.keys()))\n",
    "    \"\"\"\n",
    "    Implement the generation function.\n",
    "    \n",
    "    Args:\n",
    "        problem (dict): The problem to solve.\n",
    "        \n",
    "    Returns:\n",
    "        str: The generated code.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = generate_prompt(problem=problem)\n",
    "\n",
    "    request = CompletionRequest(\n",
    "        prompt=Prompt.from_text(prompt),\n",
    "        maximum_tokens=64,\n",
    "    )\n",
    "\n",
    "    # API reference for the client:\n",
    "    # https://aleph-alpha-client.readthedocs.io/en/latest/\n",
    "    response = client.complete(request, model=MODEL)\n",
    "    \n",
    "    # Run test cases on the generated code and iterate.\n",
    "    # test_results = run_test_cases(\n",
    "    #    problem=problem, \n",
    "    #    generation=response.completions[0].completion, \n",
    "    #    timeout=10,\n",
    "    # )\n",
    "\n",
    "    return response.completions[0].completion\n",
    "\n",
    "\n",
    "problem = load_sample(index=0, dataset_path=\"./data/dev\")\n",
    "generated_code = generate_code(problem, client)\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['problem_id', 'question', 'input_output', 'url', 'difficulty', 'starter_code']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'passed': True, 'input': [[1, 2, 7, 0, 5], 0], 'output': [5.0], 'expected_output': [5.0], 'traceback': None}]\n",
      "Passed 100.0% of problems\n",
      "Passed 100.0% of test cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utilities import score\n",
    "\n",
    "passed_problems, passed_test_cases = score(\n",
    "    generation_func=generate_code, \n",
    "    client=client,\n",
    "    dataset_path=\"./data/val\", \n",
    "    length=1,\n",
    ")\n",
    "\n",
    "print(f\"Passed {passed_problems*100}% of problems\")\n",
    "print(f\"Passed {passed_test_cases*100}% of test cases\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
